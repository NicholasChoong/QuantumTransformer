/group/pmc026/nchoong/quantum/lib/python3.11/site-packages/torchdata/datapipes/__init__.py:18: UserWarning: 
################################################################################
WARNING!
The 'datapipes', 'dataloader2' modules are deprecated and will be removed in a
future torchdata release! Please see https://github.com/pytorch/data/issues/1196
to learn more and leave feedback.
################################################################################

  deprecation_warning()
pos:  1999
neg:  2001
++ There will be 2 transformer blocks
++ Transformer will use 8 qubits and 3 q layers
The feed-forward head will use 8 qubits
weight_shapes = (n_qlayers, n_qubits) = (3, 8)
The model has 400,601 trainable parameters

Epoch   1/30: 100%|██████████| 4000/4000 [1:26:51<00:00,  1.30s/batch, Epoch = 86m 51s, Loss = 0.7024|0.6935, Acc = 0.496|0.506, AUC = 49.515|50.428]
Epoch   2/30: 100%|██████████| 4000/4000 [1:24:58<00:00,  1.27s/batch, Epoch = 84m 58s, Loss = 0.6934|0.6963, Acc = 0.518|0.496, AUC = 51.974|49.698]
Epoch   3/30: 100%|██████████| 4000/4000 [1:24:51<00:00,  1.27s/batch, Epoch = 84m 51s, Loss = 0.6925|0.6930, Acc = 0.521|0.510, AUC = 52.648|52.831]
Epoch   4/30: 100%|██████████| 4000/4000 [1:24:49<00:00,  1.27s/batch, Epoch = 84m 49s, Loss = 0.6894|0.6886, Acc = 0.535|0.542, AUC = 54.989|56.628]
Epoch   5/30: 100%|██████████| 4000/4000 [1:24:42<00:00,  1.27s/batch, Epoch = 84m 42s, Loss = 0.6896|0.6868, Acc = 0.540|0.544, AUC = 54.979|56.271]
Epoch   6/30: 100%|██████████| 4000/4000 [1:24:48<00:00,  1.27s/batch, Epoch = 84m 48s, Loss = 0.6847|0.6838, Acc = 0.558|0.562, AUC = 58.403|60.628]
Epoch   7/30: 100%|██████████| 4000/4000 [1:24:44<00:00,  1.27s/batch, Epoch = 84m 44s, Loss = 0.6798|0.6796, Acc = 0.577|0.563, AUC = 61.227|61.191]
Epoch   8/30: 100%|██████████| 4000/4000 [1:24:48<00:00,  1.27s/batch, Epoch = 84m 48s, Loss = 0.6739|0.6874, Acc = 0.593|0.530, AUC = 63.141|64.020]
Epoch   9/30: 100%|██████████| 4000/4000 [1:24:45<00:00,  1.27s/batch, Epoch = 84m 45s, Loss = 0.6666|0.6696, Acc = 0.609|0.606, AUC = 65.309|66.428]
Epoch  10/30: 100%|██████████| 4000/4000 [1:24:44<00:00,  1.27s/batch, Epoch = 84m 44s, Loss = 0.6515|0.6693, Acc = 0.640|0.590, AUC = 68.941|66.178]
Epoch  11/30: 100%|██████████| 4000/4000 [1:24:42<00:00,  1.27s/batch, Epoch = 84m 42s, Loss = 0.6404|0.6802, Acc = 0.651|0.575, AUC = 70.314|68.210]
Epoch  12/30: 100%|██████████| 4000/4000 [1:24:41<00:00,  1.27s/batch, Epoch = 84m 41s, Loss = 0.6214|0.6649, Acc = 0.671|0.614, AUC = 73.410|70.129]
Epoch  13/30: 100%|██████████| 4000/4000 [1:24:50<00:00,  1.27s/batch, Epoch = 84m 50s, Loss = 0.5990|0.6395, Acc = 0.687|0.633, AUC = 75.788|70.020]
Epoch  14/30: 100%|██████████| 4000/4000 [1:24:45<00:00,  1.27s/batch, Epoch = 84m 45s, Loss = 0.5814|0.6516, Acc = 0.710|0.619, AUC = 77.571|71.448]
Epoch  15/30: 100%|██████████| 4000/4000 [1:28:21<00:00,  1.33s/batch, Epoch = 88m 21s, Loss = 0.5620|0.6587, Acc = 0.726|0.623, AUC = 79.399|72.912]
Epoch  16/30: 100%|██████████| 4000/4000 [1:30:22<00:00,  1.36s/batch, Epoch = 90m 22s, Loss = 0.5509|0.6304, Acc = 0.722|0.640, AUC = 79.913|73.375]
Epoch  17/30: 100%|██████████| 4000/4000 [1:26:23<00:00,  1.30s/batch, Epoch = 86m 23s, Loss = 0.5393|0.6870, Acc = 0.734|0.620, AUC = 81.039|74.312]
Epoch  18/30: 100%|██████████| 4000/4000 [1:24:47<00:00,  1.27s/batch, Epoch = 84m 47s, Loss = 0.5183|0.6684, Acc = 0.748|0.644, AUC = 82.717|74.772]
Epoch  19/30: 100%|██████████| 4000/4000 [1:24:47<00:00,  1.27s/batch, Epoch = 84m 47s, Loss = 0.5087|0.6253, Acc = 0.749|0.663, AUC = 83.232|76.103]
Epoch  20/30: 100%|██████████| 4000/4000 [1:24:47<00:00,  1.27s/batch, Epoch = 84m 47s, Loss = 0.4930|0.6206, Acc = 0.758|0.671, AUC = 84.489|76.763]
Epoch  21/30: 100%|██████████| 4000/4000 [1:24:42<00:00,  1.27s/batch, Epoch = 84m 42s, Loss = 0.4853|0.6371, Acc = 0.770|0.655, AUC = 84.967|77.103]
Epoch  22/30: 100%|██████████| 4000/4000 [1:24:45<00:00,  1.27s/batch, Epoch = 84m 45s, Loss = 0.4971|0.6358, Acc = 0.764|0.657, AUC = 84.013|77.653]
Epoch  23/30: 100%|██████████| 4000/4000 [1:28:36<00:00,  1.33s/batch, Epoch = 88m 36s, Loss = 0.4612|0.6480, Acc = 0.789|0.676, AUC = 86.841|77.468]
Epoch  24/30: 100%|██████████| 4000/4000 [1:24:49<00:00,  1.27s/batch, Epoch = 84m 49s, Loss = 0.4561|0.6323, Acc = 0.786|0.679, AUC = 86.908|78.614]
Epoch  25/30: 100%|██████████| 4000/4000 [1:24:26<00:00,  1.27s/batch, Epoch = 84m 26s, Loss = 0.4549|0.6596, Acc = 0.791|0.656, AUC = 86.995|78.671]
Epoch  26/30: 100%|██████████| 4000/4000 [1:24:24<00:00,  1.27s/batch, Epoch = 84m 24s, Loss = 0.4351|0.6620, Acc = 0.800|0.671, AUC = 88.283|79.817]
Epoch  27/30: 100%|██████████| 4000/4000 [1:25:43<00:00,  1.29s/batch, Epoch = 85m 43s, Loss = 0.4374|0.6271, Acc = 0.807|0.679, AUC = 88.166|79.139]
Epoch  28/30: 100%|██████████| 4000/4000 [1:24:46<00:00,  1.27s/batch, Epoch = 84m 46s, Loss = 0.4225|0.7095, Acc = 0.804|0.662, AUC = 88.955|79.947]
Epoch  29/30: 100%|██████████| 4000/4000 [1:25:41<00:00,  1.29s/batch, Epoch = 85m 41s, Loss = 0.4229|0.6036, Acc = 0.802|0.695, AUC = 88.810|80.321]
Epoch  30/30: 100%|██████████| 4000/4000 [1:24:15<00:00,  1.26s/batch, Epoch = 84m 15s, Loss = 0.3950|0.6027, Acc = 0.827|0.717, AUC = 90.583|80.112]
TOTAL TIME = 153650.76s
BEST ACC = 0.72% AT EPOCH 30
BEST AUC = 80.32 AT EPOCH 29

