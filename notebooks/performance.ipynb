{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/group/pmc026/nchoong/QuantumTransformer'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.chdir(\"..\")\n",
    "sys.path.append(os.getcwd())\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-24 14:59:39.161163: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-24 14:59:39.173621: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-24 14:59:39.189199: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-24 14:59:39.193948: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-24 14:59:39.205474: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-24 14:59:41.842388: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Please first ``pip install -U qiskit`` to enable related functionality in translation module\n"
     ]
    }
   ],
   "source": [
    "from transformer.pytorch.main_no_embed import main\n",
    "from transformer.pytorch.utils.plots import plot_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from config import dev\n",
    "\n",
    "dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "os.environ[\"TF_DETERMINISTIC_OPS\"] = \"1\"\n",
    "os.environ[\"TF_CUDNN_DETERMINISTIC\"] = \"1\"\n",
    "tf.config.threading.set_inter_op_parallelism_threads(1)\n",
    "tf.config.threading.set_intra_op_parallelism_threads(1)\n",
    "\n",
    "os.environ[\"OMP_NUM_THREADS\"] = str(os.cpu_count())\n",
    "os.environ[\"TF_NUM_INTEROP_THREADS\"] = str(os.cpu_count())\n",
    "os.environ[\"TF_NUM_INTRAOP_THREADS\"] = str(os.cpu_count())\n",
    "\n",
    "tf.config.threading.set_intra_op_parallelism_threads(os.cpu_count())\n",
    "tf.config.threading.set_inter_op_parallelism_threads(os.cpu_count())\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data:  4000\n",
      "pos:  1979\n",
      "neg:  2021\n",
      "pos:  505\n",
      "neg:  495\n",
      "pos:  1233\n",
      "neg:  1267\n",
      "++ There will be 2 transformer blocks\n",
      "The model has 7,297 trainable parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch   1/4: 100%|██████████| 63/63 [00:02<00:00, 30.08batch/s, Epoch = 0m 2s, Loss = 0.6401|0.5691, Acc = 0.650|0.714, AUC = 70.472|83.856]\n",
      "Epoch   2/4: 100%|██████████| 63/63 [00:01<00:00, 36.05batch/s, Epoch = 0m 1s, Loss = 0.5162|0.4888, Acc = 0.756|0.759, AUC = 83.285|86.658]\n",
      "Epoch   3/4: 100%|██████████| 63/63 [00:02<00:00, 22.86batch/s, Epoch = 0m 2s, Loss = 0.4487|0.4422, Acc = 0.802|0.794, AUC = 87.735|87.934]\n",
      "Epoch   4/4: 100%|██████████| 63/63 [00:01<00:00, 42.90batch/s, Epoch = 0m 1s, Loss = 0.4209|0.4402, Acc = 0.819|0.796, AUC = 89.311|88.102]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TIME = 8.68s\n",
      "BEST ACC = 0.80% AT EPOCH 4\n",
      "BEST AUC = 88.10 AT EPOCH 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_acc, val_loss, val_acc, train_auc, val_auc, best_dict = main(\n",
    "    n_epochs=4,\n",
    "    sample_size=5000,\n",
    "    batch_size=64,\n",
    "    embed_dim=8,\n",
    "    num_heads=2,\n",
    "    num_blocks=2,\n",
    "    tqdm_disabled=False,\n",
    "    batch=True,\n",
    ")\n",
    "\n",
    "classiscal_metrics = {\n",
    "    \"train_loss\": train_loss,\n",
    "    \"train_acc\": train_acc,\n",
    "    \"val_loss\": val_loss,\n",
    "    \"val_acc\": val_acc,\n",
    "    \"train_auc\": train_auc,\n",
    "    \"val_auc\": val_auc,\n",
    "    \"best_dict\": best_dict,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantum with Pennylane GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/group/pmc026/nchoong/qt/lib/python3.11/site-packages/pennylane/devices/default_qubit_torch.py:173: PennyLaneDeprecationWarning: Use of 'default.qubit.torch' is deprecated. Instead, use 'default.qubit', which supports backpropagation. If you experience issues, reach out to the PennyLane team on the discussion forum: https://discuss.pennylane.ai/\n",
      "  warnings.warn(\n",
      "/group/pmc026/nchoong/qt/lib/python3.11/site-packages/pennylane/devices/default_qubit_legacy.py:211: PennyLaneDeprecationWarning: Use of 'default.qubit.torch' is deprecated. Instead, use 'default.qubit', which supports backpropagation. If you experience issues, reach out to the PennyLane team on the discussion forum: https://discuss.pennylane.ai/\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data:  4000\n",
      "pos:  1962\n",
      "neg:  2038\n",
      "pos:  506\n",
      "neg:  494\n",
      "pos:  1270\n",
      "neg:  1230\n",
      "++ There will be 2 transformer blocks\n",
      "++ Transformer will use 8 qubits and 3 q layers\n",
      "The feed-forward head will use 8 qubits\n",
      "Using PennyLane quantum device default.qubit.torch\n",
      "weight_shapes = (n_qlayers, n_qubits) = (3, 8)\n",
      "The model has 6,753 trainable parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch   1/4: 100%|██████████| 63/63 [42:10<00:00, 40.17s/batch, Epoch = 42m 10s, Loss = 0.6612|0.5767, Acc = 0.610|0.770, AUC = 67.374|85.950]\n",
      "Epoch   2/4: 100%|██████████| 63/63 [40:18<00:00, 38.39s/batch, Epoch = 40m 18s, Loss = 0.5603|0.5304, Acc = 0.762|0.744, AUC = 84.141|87.303]\n",
      "Epoch   3/4: 100%|██████████| 63/63 [41:31<00:00, 39.55s/batch, Epoch = 41m 31s, Loss = 0.5082|0.4757, Acc = 0.785|0.794, AUC = 86.155|88.207]\n",
      "Epoch   4/4: 100%|██████████| 63/63 [41:48<00:00, 39.81s/batch, Epoch = 41m 48s, Loss = 0.4763|0.4578, Acc = 0.802|0.796, AUC = 88.021|88.366]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TIME = 9948.50s\n",
      "BEST ACC = 0.80% AT EPOCH 4\n",
      "BEST AUC = 88.37 AT EPOCH 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_acc, val_loss, val_acc, train_auc, val_auc, best_dict = main(\n",
    "    n_epochs=4,\n",
    "    sample_size=5000,\n",
    "    batch_size=64,\n",
    "    embed_dim=8,\n",
    "    num_heads=2,\n",
    "    num_blocks=2,\n",
    "    n_qubits_transformer=8,\n",
    "    n_qubits_ffn=8,\n",
    "    n_qlayers=3,\n",
    "    tqdm_disabled=False,\n",
    "    q_device=\"default.qubit.torch\",\n",
    "    batch=False,\n",
    "    circuit_type=\"pennylane\",\n",
    ")\n",
    "\n",
    "quantum_pl_gpu_metrics = {\n",
    "    \"train_loss\": train_loss,\n",
    "    \"train_acc\": train_acc,\n",
    "    \"val_loss\": val_loss,\n",
    "    \"val_acc\": val_acc,\n",
    "    \"train_auc\": train_auc,\n",
    "    \"val_auc\": val_auc,\n",
    "    \"best_dict\": best_dict,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantum with Pennylane CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data:  4000\n",
      "pos:  2014\n",
      "neg:  1986\n",
      "pos:  474\n",
      "neg:  526\n",
      "pos:  1206\n",
      "neg:  1294\n",
      "++ There will be 2 transformer blocks\n",
      "++ Transformer will use 8 qubits and 3 q layers\n",
      "The feed-forward head will use 8 qubits\n",
      "Using PennyLane quantum device default.qubit\n",
      "weight_shapes = (n_qlayers, n_qubits) = (3, 8)\n",
      "The model has 6,753 trainable parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch   1/4:   0%|          | 0/63 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch   1/4: 100%|██████████| 63/63 [57:33<00:00, 54.82s/batch, Epoch = 57m 33s, Loss = 0.6675|0.5823, Acc = 0.618|0.757, AUC = 65.804|85.028]\n",
      "Epoch   2/4: 100%|██████████| 63/63 [55:31<00:00, 52.89s/batch, Epoch = 55m 31s, Loss = 0.5747|0.5467, Acc = 0.746|0.732, AUC = 82.750|86.684]\n",
      "Epoch   3/4: 100%|██████████| 63/63 [55:32<00:00, 52.90s/batch, Epoch = 55m 32s, Loss = 0.5154|0.5850, Acc = 0.782|0.684, AUC = 86.517|87.166]\n",
      "Epoch   4/4: 100%|██████████| 63/63 [54:54<00:00, 52.30s/batch, Epoch = 54m 54s, Loss = 0.4926|0.4769, Acc = 0.787|0.789, AUC = 87.304|87.588]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TIME = 13413.26s\n",
      "BEST ACC = 0.79% AT EPOCH 4\n",
      "BEST AUC = 87.59 AT EPOCH 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_acc, val_loss, val_acc, train_auc, val_auc, best_dict = main(\n",
    "    n_epochs=4,\n",
    "    sample_size=5000,\n",
    "    batch_size=64,\n",
    "    embed_dim=8,\n",
    "    num_heads=2,\n",
    "    num_blocks=2,\n",
    "    n_qubits_transformer=8,\n",
    "    n_qubits_ffn=8,\n",
    "    n_qlayers=3,\n",
    "    tqdm_disabled=False,\n",
    "    q_device=\"default.qubit\",\n",
    "    batch=False,\n",
    "    circuit_type=\"pennylane\",\n",
    ")\n",
    "\n",
    "quantum_pl_cpu_metrics = {\n",
    "    \"train_loss\": train_loss,\n",
    "    \"train_acc\": train_acc,\n",
    "    \"val_loss\": val_loss,\n",
    "    \"val_acc\": val_acc,\n",
    "    \"train_auc\": train_auc,\n",
    "    \"val_auc\": val_auc,\n",
    "    \"best_dict\": best_dict,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantum with Pennylane GPU and Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/group/pmc026/nchoong/qt/lib/python3.11/site-packages/pennylane/devices/default_qubit_torch.py:173: PennyLaneDeprecationWarning: Use of 'default.qubit.torch' is deprecated. Instead, use 'default.qubit', which supports backpropagation. If you experience issues, reach out to the PennyLane team on the discussion forum: https://discuss.pennylane.ai/\n",
      "  warnings.warn(\n",
      "/group/pmc026/nchoong/qt/lib/python3.11/site-packages/pennylane/devices/default_qubit_legacy.py:211: PennyLaneDeprecationWarning: Use of 'default.qubit.torch' is deprecated. Instead, use 'default.qubit', which supports backpropagation. If you experience issues, reach out to the PennyLane team on the discussion forum: https://discuss.pennylane.ai/\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data:  4000\n",
      "pos:  2044\n",
      "neg:  1956\n",
      "pos:  497\n",
      "neg:  503\n",
      "pos:  1272\n",
      "neg:  1228\n",
      "++ There will be 2 transformer blocks\n",
      "++ Transformer will use 8 qubits and 3 q layers\n",
      "The feed-forward head will use 8 qubits\n",
      "Using PennyLane quantum device default.qubit.torch\n",
      "weight_shapes = (n_qlayers, n_qubits) = (3, 8)\n",
      "The model has 6,753 trainable parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch   1/4: 100%|██████████| 63/63 [01:27<00:00,  1.38s/batch, Epoch = 1m 27s, Loss = 0.6784|0.6062, Acc = 0.558|0.718, AUC = 59.375|85.048]\n",
      "Epoch   2/4: 100%|██████████| 63/63 [01:24<00:00,  1.34s/batch, Epoch = 1m 24s, Loss = 0.5832|0.5576, Acc = 0.747|0.706, AUC = 81.866|86.360]\n",
      "Epoch   3/4: 100%|██████████| 63/63 [01:24<00:00,  1.35s/batch, Epoch = 1m 24s, Loss = 0.5288|0.5110, Acc = 0.769|0.745, AUC = 85.159|87.002]\n",
      "Epoch   4/4: 100%|██████████| 63/63 [01:24<00:00,  1.34s/batch, Epoch = 1m 24s, Loss = 0.4915|0.4838, Acc = 0.796|0.774, AUC = 87.707|87.214]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TIME = 340.71s\n",
      "BEST ACC = 0.77% AT EPOCH 4\n",
      "BEST AUC = 87.21 AT EPOCH 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_acc, val_loss, val_acc, train_auc, val_auc, best_dict = main(\n",
    "    n_epochs=4,\n",
    "    sample_size=5000,\n",
    "    batch_size=64,\n",
    "    embed_dim=8,\n",
    "    num_heads=2,\n",
    "    num_blocks=2,\n",
    "    n_qubits_transformer=8,\n",
    "    n_qubits_ffn=8,\n",
    "    n_qlayers=3,\n",
    "    tqdm_disabled=False,\n",
    "    q_device=\"default.qubit.torch\",\n",
    "    batch=True,\n",
    "    circuit_type=\"pennylane\",\n",
    ")\n",
    "\n",
    "quantum_pl_gpu_metrics_batch = {\n",
    "    \"train_loss\": train_loss,\n",
    "    \"train_acc\": train_acc,\n",
    "    \"val_loss\": val_loss,\n",
    "    \"val_acc\": val_acc,\n",
    "    \"train_auc\": train_auc,\n",
    "    \"val_auc\": val_auc,\n",
    "    \"best_dict\": best_dict,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantum with Pennylane CPU and Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data:  4000\n",
      "pos:  1985\n",
      "neg:  2015\n",
      "pos:  505\n",
      "neg:  495\n",
      "pos:  1260\n",
      "neg:  1240\n",
      "++ There will be 2 transformer blocks\n",
      "++ Transformer will use 8 qubits and 3 q layers\n",
      "The feed-forward head will use 8 qubits\n",
      "Using PennyLane quantum device default.qubit\n",
      "weight_shapes = (n_qlayers, n_qubits) = (3, 8)\n",
      "The model has 6,753 trainable parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch   1/4: 100%|██████████| 63/63 [01:59<00:00,  1.90s/batch, Epoch = 1m 59s, Loss = 0.6495|0.5641, Acc = 0.636|0.736, AUC = 68.409|82.882]\n",
      "Epoch   2/4: 100%|██████████| 63/63 [02:01<00:00,  1.92s/batch, Epoch = 2m 1s, Loss = 0.5290|0.5218, Acc = 0.776|0.739, AUC = 84.919|84.557]\n",
      "Epoch   3/4: 100%|██████████| 63/63 [01:59<00:00,  1.90s/batch, Epoch = 1m 59s, Loss = 0.4824|0.4833, Acc = 0.797|0.771, AUC = 87.092|85.415]\n",
      "Epoch   4/4: 100%|██████████| 63/63 [02:03<00:00,  1.96s/batch, Epoch = 2m 3s, Loss = 0.4525|0.4883, Acc = 0.813|0.764, AUC = 88.654|85.487]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TIME = 483.71s\n",
      "BEST ACC = 0.77% AT EPOCH 3\n",
      "BEST AUC = 85.49 AT EPOCH 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_acc, val_loss, val_acc, train_auc, val_auc, best_dict = main(\n",
    "    n_epochs=4,\n",
    "    sample_size=5000,\n",
    "    batch_size=64,\n",
    "    embed_dim=8,\n",
    "    num_heads=2,\n",
    "    num_blocks=2,\n",
    "    n_qubits_transformer=8,\n",
    "    n_qubits_ffn=8,\n",
    "    n_qlayers=3,\n",
    "    tqdm_disabled=False,\n",
    "    q_device=\"default.qubit\",\n",
    "    batch=True,\n",
    "    circuit_type=\"pennylane\",\n",
    ")\n",
    "\n",
    "quantum_pl_cpu_metrics_batch = {\n",
    "    \"train_loss\": train_loss,\n",
    "    \"train_acc\": train_acc,\n",
    "    \"val_loss\": val_loss,\n",
    "    \"val_acc\": val_acc,\n",
    "    \"train_auc\": train_auc,\n",
    "    \"val_auc\": val_auc,\n",
    "    \"best_dict\": best_dict,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantum with Tensorcircuit (Tensorflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data:  4000\n",
      "pos:  2008\n",
      "neg:  1992\n",
      "pos:  525\n",
      "neg:  475\n",
      "pos:  1292\n",
      "neg:  1208\n",
      "++ There will be 2 transformer blocks\n",
      "++ Transformer will use 8 qubits and 3 q layers\n",
      "The feed-forward head will use 8 qubits\n",
      "Using TensorCircuit\n",
      "weight_shapes = (n_qlayers, n_qubits) = (3, 8)\n",
      "The model has 6,753 trainable parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch   1/4: 100%|██████████| 63/63 [32:09<00:00, 30.62s/batch, Epoch = 32m 9s, Loss = 0.6526|0.5506, Acc = 0.622|0.789, AUC = 67.765|87.201]\n",
      "Epoch   2/4: 100%|██████████| 63/63 [31:18<00:00, 29.82s/batch, Epoch = 31m 18s, Loss = 0.5287|0.5079, Acc = 0.778|0.754, AUC = 85.330|88.927]\n",
      "Epoch   3/4: 100%|██████████| 63/63 [30:05<00:00, 28.65s/batch, Epoch = 30m 5s, Loss = 0.4834|0.4423, Acc = 0.790|0.821, AUC = 87.018|89.550]\n",
      "Epoch   4/4: 100%|██████████| 63/63 [27:27<00:00, 26.14s/batch, Epoch = 27m 27s, Loss = 0.4482|0.4400, Acc = 0.816|0.812, AUC = 89.517|89.571]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TIME = 7259.99s\n",
      "BEST ACC = 0.82% AT EPOCH 3\n",
      "BEST AUC = 89.57 AT EPOCH 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_acc, val_loss, val_acc, train_auc, val_auc, best_dict = main(\n",
    "    n_epochs=4,\n",
    "    sample_size=5000,\n",
    "    batch_size=64,\n",
    "    embed_dim=8,\n",
    "    num_heads=2,\n",
    "    num_blocks=2,\n",
    "    n_qubits_transformer=8,\n",
    "    n_qubits_ffn=8,\n",
    "    n_qlayers=3,\n",
    "    tqdm_disabled=False,\n",
    "    batch=False,\n",
    "    circuit_type=\"tensorcircuit\",\n",
    ")\n",
    "\n",
    "quantum_tc_cpu_metrics = {\n",
    "    \"train_loss\": train_loss,\n",
    "    \"train_acc\": train_acc,\n",
    "    \"val_loss\": val_loss,\n",
    "    \"val_acc\": val_acc,\n",
    "    \"train_auc\": train_auc,\n",
    "    \"val_auc\": val_auc,\n",
    "    \"best_dict\": best_dict,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantum with Tensorcircuit (Tensorflow) and Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data:  4000\n",
      "pos:  2024\n",
      "neg:  1976\n",
      "pos:  499\n",
      "neg:  501\n",
      "pos:  1271\n",
      "neg:  1229\n",
      "++ There will be 2 transformer blocks\n",
      "++ Transformer will use 8 qubits and 3 q layers\n",
      "The feed-forward head will use 8 qubits\n",
      "Using TensorCircuit\n",
      "weight_shapes = (n_qlayers, n_qubits) = (3, 8)\n",
      "The model has 6,753 trainable parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch   1/4:   0%|          | 0/63 [00:00<?, ?batch/s]2024-09-24 15:14:54.002367: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2024-09-24 15:14:54.002519: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8246 MB memory:  -> device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:3b:00.0, compute capability: 7.0\n",
      "2024-09-24 15:14:54.002815: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2024-09-24 15:14:54.002974: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 30828 MB memory:  -> device: 1, name: Tesla V100-PCIE-32GB, pci bus id: 0000:d8:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowBackend.vmap.<locals>.wrapper at 0x7f3bb3b57420> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function torch_interface.<locals>.vjp_fun at 0x7f3bbbae9ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch   1/4:  98%|█████████▊| 62/63 [01:25<00:00,  1.99batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 620 calls to <function TensorFlowBackend.vmap.<locals>.wrapper at 0x7f3bb3b56de0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 620 calls to <function torch_interface.<locals>.vjp_fun at 0x7f3bb3b576a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch   1/4: 100%|██████████| 63/63 [02:49<00:00,  2.70s/batch, Epoch = 2m 49s, Loss = 0.6674|0.6166, Acc = 0.606|0.681, AUC = 64.764|83.010]\n",
      "Epoch   2/4: 100%|██████████| 63/63 [00:35<00:00,  1.76batch/s, Epoch = 0m 35s, Loss = 0.5737|0.5644, Acc = 0.762|0.710, AUC = 83.364|84.974]\n",
      "Epoch   3/4: 100%|██████████| 63/63 [00:34<00:00,  1.82batch/s, Epoch = 0m 34s, Loss = 0.5279|0.4978, Acc = 0.764|0.780, AUC = 84.461|86.164]\n",
      "Epoch   4/4: 100%|██████████| 63/63 [00:35<00:00,  1.76batch/s, Epoch = 0m 35s, Loss = 0.4869|0.4881, Acc = 0.806|0.774, AUC = 87.951|86.239]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TIME = 276.00s\n",
      "BEST ACC = 0.78% AT EPOCH 3\n",
      "BEST AUC = 86.24 AT EPOCH 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_acc, val_loss, val_acc, train_auc, val_auc, best_dict = main(\n",
    "    n_epochs=4,\n",
    "    sample_size=5000,\n",
    "    batch_size=64,\n",
    "    embed_dim=8,\n",
    "    num_heads=2,\n",
    "    num_blocks=2,\n",
    "    n_qubits_transformer=8,\n",
    "    n_qubits_ffn=8,\n",
    "    n_qlayers=3,\n",
    "    tqdm_disabled=False,\n",
    "    batch=True,\n",
    "    circuit_type=\"tensorcircuit\",\n",
    ")\n",
    "\n",
    "quantum_tc_cpu_metrics_batch = {\n",
    "    \"train_loss\": train_loss,\n",
    "    \"train_acc\": train_acc,\n",
    "    \"val_loss\": val_loss,\n",
    "    \"val_acc\": val_acc,\n",
    "    \"train_auc\": train_auc,\n",
    "    \"val_auc\": val_auc,\n",
    "    \"best_dict\": best_dict,\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
