{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/group/pmc026/nchoong/QuantumTransformer'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.chdir(\"..\")\n",
    "sys.path.append(os.getcwd())\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-05 09:37:10.616708: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-05 09:37:10.629346: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-05 09:37:10.644907: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-05 09:37:10.649645: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-05 09:37:10.661467: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-05 09:37:13.123732: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Please first ``pip install -U qiskit`` to enable related functionality in translation module\n"
     ]
    }
   ],
   "source": [
    "from transformer.pytorch.main_no_embed import main\n",
    "from transformer.pytorch.utils.load_dataloader import load_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from config import dev\n",
    "\n",
    "dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "os.environ[\"TF_DETERMINISTIC_OPS\"] = \"1\"\n",
    "os.environ[\"TF_CUDNN_DETERMINISTIC\"] = \"1\"\n",
    "tf.config.threading.set_inter_op_parallelism_threads(1)\n",
    "tf.config.threading.set_intra_op_parallelism_threads(1)\n",
    "\n",
    "os.environ[\"OMP_NUM_THREADS\"] = str(os.cpu_count())\n",
    "os.environ[\"TF_NUM_INTEROP_THREADS\"] = str(os.cpu_count())\n",
    "os.environ[\"TF_NUM_INTRAOP_THREADS\"] = str(os.cpu_count())\n",
    "\n",
    "tf.config.threading.set_intra_op_parallelism_threads(os.cpu_count())\n",
    "tf.config.threading.set_inter_op_parallelism_threads(os.cpu_count())\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading train tensors: 100%|██████████| 7/7 [00:03<00:00,  2.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size:  5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading val tensors: 100%|██████████| 2/2 [00:00<00:00,  2.61it/s]\n",
      "Loading test tensors: 100%|██████████| 9/9 [00:03<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test size:  5000\n",
      "Sampled train tensor shape:  torch.Size([20000, 128, 768])\n",
      "Sampled val tensor shape:  torch.Size([5000, 128, 768])\n",
      "Sampled test tensor shape:  torch.Size([5000, 128, 768])\n",
      "Train, Val, Test size:  20000 5000 5000\n",
      "pos:  10006\n",
      "neg:  9994\n",
      "pos:  2494\n",
      "neg:  2506\n",
      "pos:  2515\n",
      "neg:  2485\n"
     ]
    }
   ],
   "source": [
    "train_dataloader, val_dataloader, test_dataloader = load_dataloader(\"imdb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++ There will be 2 transformer blocks\n",
      "TextClassifier(\n",
      "  (squeeze): Linear(in_features=768, out_features=8, bias=True)\n",
      "  (transformers): ModuleList(\n",
      "    (0-1): 2 x Encoder(\n",
      "      (attn): MultiHeadedAttention(\n",
      "        (linears): ModuleList(\n",
      "          (0-2): 3 x Linear(in_features=8, out_features=8, bias=False)\n",
      "        )\n",
      "        (combine_heads): Linear(in_features=8, out_features=8, bias=False)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (norm1): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout1): Dropout(p=0.1, inplace=False)\n",
      "      (ffn): FeedForward(\n",
      "        (linear_1): Linear(in_features=8, out_features=16, bias=True)\n",
      "        (linear_2): Linear(in_features=16, out_features=8, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (norm2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout2): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (layer_norm): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "  (class_logits): Linear(in_features=8, out_features=1, bias=True)\n",
      ")\n",
      "Layer Name                               Number of Parameters\n",
      "============================================================\n",
      "squeeze.weight                           6144\n",
      "squeeze.bias                             8\n",
      "transformers.0.attn.linears.0.weight     64\n",
      "transformers.0.attn.linears.1.weight     64\n",
      "transformers.0.attn.linears.2.weight     64\n",
      "transformers.0.attn.combine_heads.weight 64\n",
      "transformers.0.norm1.weight              8\n",
      "transformers.0.norm1.bias                8\n",
      "transformers.0.ffn.linear_1.weight       128\n",
      "transformers.0.ffn.linear_1.bias         16\n",
      "transformers.0.ffn.linear_2.weight       128\n",
      "transformers.0.ffn.linear_2.bias         8\n",
      "transformers.0.norm2.weight              8\n",
      "transformers.0.norm2.bias                8\n",
      "transformers.1.attn.linears.0.weight     64\n",
      "transformers.1.attn.linears.1.weight     64\n",
      "transformers.1.attn.linears.2.weight     64\n",
      "transformers.1.attn.combine_heads.weight 64\n",
      "transformers.1.norm1.weight              8\n",
      "transformers.1.norm1.bias                8\n",
      "transformers.1.ffn.linear_1.weight       128\n",
      "transformers.1.ffn.linear_1.bias         16\n",
      "transformers.1.ffn.linear_2.weight       128\n",
      "transformers.1.ffn.linear_2.bias         8\n",
      "transformers.1.norm2.weight              8\n",
      "transformers.1.norm2.bias                8\n",
      "layer_norm.weight                        8\n",
      "layer_norm.bias                          8\n",
      "class_logits.weight                      8\n",
      "class_logits.bias                        1\n",
      "The model has 7,313 trainable parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch   1/4: 100%|██████████| 313/313 [00:13<00:00, 23.26batch/s, Epoch = 0m 13s, Loss = 0.5751|0.5505, Acc = 0.697|0.734, AUC = 76.891|88.726]\n",
      "Epoch   2/4: 100%|██████████| 313/313 [00:06<00:00, 49.02batch/s, Epoch = 0m 6s, Loss = 0.4376|0.3881, Acc = 0.813|0.838, AUC = 87.803|91.900]\n",
      "Epoch   3/4: 100%|██████████| 313/313 [00:05<00:00, 59.89batch/s, Epoch = 0m 5s, Loss = 0.3958|0.3966, Acc = 0.834|0.828, AUC = 90.177|92.570]\n",
      "Epoch   4/4: 100%|██████████| 313/313 [00:07<00:00, 44.59batch/s, Epoch = 0m 7s, Loss = 0.3748|0.3592, Acc = 0.842|0.842, AUC = 91.251|92.599]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TIME = 32.69s\n",
      "BEST ACC = 0.84% AT EPOCH 4\n",
      "BEST AUC = 92.60 AT EPOCH 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_acc, val_loss, val_acc, train_auc, val_auc, best_dict = main(\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    n_epochs=4,\n",
    "    sample_size=0,\n",
    "    batch_size=64,\n",
    "    embed_dim=8,\n",
    "    num_heads=2,\n",
    "    num_blocks=2,\n",
    "    tqdm_disabled=False,\n",
    "    batch=True,\n",
    ")\n",
    "\n",
    "classiscal_metrics = {\n",
    "    \"train_loss\": train_loss,\n",
    "    \"train_acc\": train_acc,\n",
    "    \"val_loss\": val_loss,\n",
    "    \"val_acc\": val_acc,\n",
    "    \"train_auc\": train_auc,\n",
    "    \"val_auc\": val_auc,\n",
    "    \"best_dict\": best_dict,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantum with Pennylane GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++ There will be 2 transformer blocks\n",
      "++ Transformer will use 8 qubits and 3 q layers\n",
      "The feed-forward head will use 8 qubits\n",
      "Using PennyLane quantum device default.qubit.torch\n",
      "weight_shapes = (n_qlayers, n_qubits) = (3, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/group/pmc026/nchoong/qt/lib/python3.11/site-packages/pennylane/devices/default_qubit_torch.py:173: PennyLaneDeprecationWarning: Use of 'default.qubit.torch' is deprecated. Instead, use 'default.qubit', which supports backpropagation. If you experience issues, reach out to the PennyLane team on the discussion forum: https://discuss.pennylane.ai/\n",
      "  warnings.warn(\n",
      "/group/pmc026/nchoong/qt/lib/python3.11/site-packages/pennylane/devices/default_qubit_legacy.py:211: PennyLaneDeprecationWarning: Use of 'default.qubit.torch' is deprecated. Instead, use 'default.qubit', which supports backpropagation. If you experience issues, reach out to the PennyLane team on the discussion forum: https://discuss.pennylane.ai/\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight_shapes = (n_qlayers, n_qubits) = (3, 8)\n",
      "TextClassifier(\n",
      "  (squeeze): Linear(in_features=768, out_features=8, bias=True)\n",
      "  (transformers): ModuleList(\n",
      "    (0-1): 2 x Encoder(\n",
      "      (attn): MultiHeadedAttention(\n",
      "        (k_linear): QuantumLayer(\n",
      "          (linear): <Quantum Torch Layer: func=qlayer>\n",
      "        )\n",
      "        (q_linear): QuantumLayer(\n",
      "          (linear): <Quantum Torch Layer: func=qlayer>\n",
      "        )\n",
      "        (v_linear): QuantumLayer(\n",
      "          (linear): <Quantum Torch Layer: func=qlayer>\n",
      "        )\n",
      "        (combine_heads): QuantumLayer(\n",
      "          (linear): <Quantum Torch Layer: func=qlayer>\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (norm1): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout1): Dropout(p=0.1, inplace=False)\n",
      "      (ffn): FeedForward(\n",
      "        (linear_1): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (linear_2): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (vqc): QuantumLayer(\n",
      "          (linear): <Quantum Torch Layer: func=qlayer>\n",
      "        )\n",
      "        (gelu): GELU(approximate='none')\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (norm2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout2): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (layer_norm): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "  (class_logits): Linear(in_features=8, out_features=1, bias=True)\n",
      ")\n",
      "Layer Name                               Number of Parameters\n",
      "============================================================\n",
      "squeeze.weight                           6144\n",
      "squeeze.bias                             8\n",
      "transformers.0.attn.k_linear.linear.weights 24\n",
      "transformers.0.attn.q_linear.linear.weights 24\n",
      "transformers.0.attn.v_linear.linear.weights 24\n",
      "transformers.0.attn.combine_heads.linear.weights 24\n",
      "transformers.0.norm1.weight              8\n",
      "transformers.0.norm1.bias                8\n",
      "transformers.0.ffn.linear_1.weight       64\n",
      "transformers.0.ffn.linear_1.bias         8\n",
      "transformers.0.ffn.linear_2.weight       64\n",
      "transformers.0.ffn.linear_2.bias         8\n",
      "transformers.0.ffn.vqc.linear.weights    24\n",
      "transformers.0.norm2.weight              8\n",
      "transformers.0.norm2.bias                8\n",
      "transformers.1.attn.k_linear.linear.weights 24\n",
      "transformers.1.attn.q_linear.linear.weights 24\n",
      "transformers.1.attn.v_linear.linear.weights 24\n",
      "transformers.1.attn.combine_heads.linear.weights 24\n",
      "transformers.1.norm1.weight              8\n",
      "transformers.1.norm1.bias                8\n",
      "transformers.1.ffn.linear_1.weight       64\n",
      "transformers.1.ffn.linear_1.bias         8\n",
      "transformers.1.ffn.linear_2.weight       64\n",
      "transformers.1.ffn.linear_2.bias         8\n",
      "transformers.1.ffn.vqc.linear.weights    24\n",
      "transformers.1.norm2.weight              8\n",
      "transformers.1.norm2.bias                8\n",
      "layer_norm.weight                        8\n",
      "layer_norm.bias                          8\n",
      "class_logits.weight                      8\n",
      "class_logits.bias                        1\n",
      "The model has 6,769 trainable parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch   1/4:  65%|██████▍   | 203/313 [2:05:38<1:07:54, 37.04s/batch]"
     ]
    }
   ],
   "source": [
    "train_loss, train_acc, val_loss, val_acc, train_auc, val_auc, best_dict = main(\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    n_epochs=4,\n",
    "    sample_size=0,\n",
    "    batch_size=64,\n",
    "    embed_dim=8,\n",
    "    num_heads=2,\n",
    "    num_blocks=2,\n",
    "    n_qubits_transformer=8,\n",
    "    n_qubits_ffn=8,\n",
    "    n_qlayers=3,\n",
    "    tqdm_disabled=False,\n",
    "    q_device=\"default.qubit.torch\",\n",
    "    batch=False,\n",
    "    circuit_type=\"pennylane\",\n",
    ")\n",
    "\n",
    "quantum_pl_gpu_metrics = {\n",
    "    \"train_loss\": train_loss,\n",
    "    \"train_acc\": train_acc,\n",
    "    \"val_loss\": val_loss,\n",
    "    \"val_acc\": val_acc,\n",
    "    \"train_auc\": train_auc,\n",
    "    \"val_auc\": val_auc,\n",
    "    \"best_dict\": best_dict,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantum with Pennylane CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data:  4000\n",
      "pos:  2014\n",
      "neg:  1986\n",
      "pos:  474\n",
      "neg:  526\n",
      "pos:  1206\n",
      "neg:  1294\n",
      "++ There will be 2 transformer blocks\n",
      "++ Transformer will use 8 qubits and 3 q layers\n",
      "The feed-forward head will use 8 qubits\n",
      "Using PennyLane quantum device default.qubit\n",
      "weight_shapes = (n_qlayers, n_qubits) = (3, 8)\n",
      "The model has 6,753 trainable parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch   1/4:   0%|          | 0/63 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch   1/4: 100%|██████████| 63/63 [57:33<00:00, 54.82s/batch, Epoch = 57m 33s, Loss = 0.6675|0.5823, Acc = 0.618|0.757, AUC = 65.804|85.028]\n",
      "Epoch   2/4: 100%|██████████| 63/63 [55:31<00:00, 52.89s/batch, Epoch = 55m 31s, Loss = 0.5747|0.5467, Acc = 0.746|0.732, AUC = 82.750|86.684]\n",
      "Epoch   3/4: 100%|██████████| 63/63 [55:32<00:00, 52.90s/batch, Epoch = 55m 32s, Loss = 0.5154|0.5850, Acc = 0.782|0.684, AUC = 86.517|87.166]\n",
      "Epoch   4/4: 100%|██████████| 63/63 [54:54<00:00, 52.30s/batch, Epoch = 54m 54s, Loss = 0.4926|0.4769, Acc = 0.787|0.789, AUC = 87.304|87.588]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TIME = 13413.26s\n",
      "BEST ACC = 0.79% AT EPOCH 4\n",
      "BEST AUC = 87.59 AT EPOCH 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_acc, val_loss, val_acc, train_auc, val_auc, best_dict = main(\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    n_epochs=4,\n",
    "    sample_size=0,\n",
    "    batch_size=64,\n",
    "    embed_dim=8,\n",
    "    num_heads=2,\n",
    "    num_blocks=2,\n",
    "    n_qubits_transformer=8,\n",
    "    n_qubits_ffn=8,\n",
    "    n_qlayers=3,\n",
    "    tqdm_disabled=False,\n",
    "    q_device=\"default.qubit\",\n",
    "    batch=False,\n",
    "    circuit_type=\"pennylane\",\n",
    ")\n",
    "\n",
    "quantum_pl_cpu_metrics = {\n",
    "    \"train_loss\": train_loss,\n",
    "    \"train_acc\": train_acc,\n",
    "    \"val_loss\": val_loss,\n",
    "    \"val_acc\": val_acc,\n",
    "    \"train_auc\": train_auc,\n",
    "    \"val_auc\": val_auc,\n",
    "    \"best_dict\": best_dict,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantum with Pennylane GPU and Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/group/pmc026/nchoong/qt/lib/python3.11/site-packages/pennylane/devices/default_qubit_torch.py:173: PennyLaneDeprecationWarning: Use of 'default.qubit.torch' is deprecated. Instead, use 'default.qubit', which supports backpropagation. If you experience issues, reach out to the PennyLane team on the discussion forum: https://discuss.pennylane.ai/\n",
      "  warnings.warn(\n",
      "/group/pmc026/nchoong/qt/lib/python3.11/site-packages/pennylane/devices/default_qubit_legacy.py:211: PennyLaneDeprecationWarning: Use of 'default.qubit.torch' is deprecated. Instead, use 'default.qubit', which supports backpropagation. If you experience issues, reach out to the PennyLane team on the discussion forum: https://discuss.pennylane.ai/\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++ There will be 2 transformer blocks\n",
      "++ Transformer will use 8 qubits and 3 q layers\n",
      "The feed-forward head will use 8 qubits\n",
      "Using PennyLane quantum device default.qubit.torch\n",
      "weight_shapes = (n_qlayers, n_qubits) = (3, 8)\n",
      "weight_shapes = (n_qlayers, n_qubits) = (3, 8)\n",
      "TextClassifier(\n",
      "  (squeeze): Linear(in_features=768, out_features=8, bias=True)\n",
      "  (transformers): ModuleList(\n",
      "    (0-1): 2 x Encoder(\n",
      "      (attn): MultiHeadedAttention(\n",
      "        (k_linear): QuantumLayer(\n",
      "          (linear): <Quantum Torch Layer: func=qlayer>\n",
      "        )\n",
      "        (q_linear): QuantumLayer(\n",
      "          (linear): <Quantum Torch Layer: func=qlayer>\n",
      "        )\n",
      "        (v_linear): QuantumLayer(\n",
      "          (linear): <Quantum Torch Layer: func=qlayer>\n",
      "        )\n",
      "        (combine_heads): QuantumLayer(\n",
      "          (linear): <Quantum Torch Layer: func=qlayer>\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (norm1): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout1): Dropout(p=0.1, inplace=False)\n",
      "      (ffn): FeedForward(\n",
      "        (linear_1): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (linear_2): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (vqc): QuantumLayer(\n",
      "          (linear): <Quantum Torch Layer: func=qlayer>\n",
      "        )\n",
      "        (gelu): GELU(approximate='none')\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (norm2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout2): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (layer_norm): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "  (class_logits): Linear(in_features=8, out_features=1, bias=True)\n",
      ")\n",
      "Layer Name                               Number of Parameters\n",
      "============================================================\n",
      "squeeze.weight                           6144\n",
      "squeeze.bias                             8\n",
      "transformers.0.attn.k_linear.linear.weights 24\n",
      "transformers.0.attn.q_linear.linear.weights 24\n",
      "transformers.0.attn.v_linear.linear.weights 24\n",
      "transformers.0.attn.combine_heads.linear.weights 24\n",
      "transformers.0.norm1.weight              8\n",
      "transformers.0.norm1.bias                8\n",
      "transformers.0.ffn.linear_1.weight       64\n",
      "transformers.0.ffn.linear_1.bias         8\n",
      "transformers.0.ffn.linear_2.weight       64\n",
      "transformers.0.ffn.linear_2.bias         8\n",
      "transformers.0.ffn.vqc.linear.weights    24\n",
      "transformers.0.norm2.weight              8\n",
      "transformers.0.norm2.bias                8\n",
      "transformers.1.attn.k_linear.linear.weights 24\n",
      "transformers.1.attn.q_linear.linear.weights 24\n",
      "transformers.1.attn.v_linear.linear.weights 24\n",
      "transformers.1.attn.combine_heads.linear.weights 24\n",
      "transformers.1.norm1.weight              8\n",
      "transformers.1.norm1.bias                8\n",
      "transformers.1.ffn.linear_1.weight       64\n",
      "transformers.1.ffn.linear_1.bias         8\n",
      "transformers.1.ffn.linear_2.weight       64\n",
      "transformers.1.ffn.linear_2.bias         8\n",
      "transformers.1.ffn.vqc.linear.weights    24\n",
      "transformers.1.norm2.weight              8\n",
      "transformers.1.norm2.bias                8\n",
      "layer_norm.weight                        8\n",
      "layer_norm.bias                          8\n",
      "class_logits.weight                      8\n",
      "class_logits.bias                        1\n",
      "The model has 6,769 trainable parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch   1/4:   0%|          | 0/313 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch   1/4: 100%|██████████| 313/313 [07:15<00:00,  1.39s/batch, Epoch = 7m 15s, Loss = 0.5866|0.4986, Acc = 0.690|0.765, AUC = 75.861|85.852]\n",
      "Epoch   2/4: 100%|██████████| 313/313 [07:11<00:00,  1.38s/batch, Epoch = 7m 11s, Loss = 0.5037|0.5126, Acc = 0.767|0.764, AUC = 83.448|86.359]\n",
      "Epoch   3/4: 100%|██████████| 313/313 [07:07<00:00,  1.36s/batch, Epoch = 7m 7s, Loss = 0.4964|0.4700, Acc = 0.771|0.786, AUC = 84.062|86.854]\n",
      "Epoch   4/4: 100%|██████████| 313/313 [07:10<00:00,  1.38s/batch, Epoch = 7m 10s, Loss = 0.4838|0.4584, Acc = 0.779|0.785, AUC = 85.013|87.325]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TIME = 1724.79s\n",
      "BEST ACC = 0.79% AT EPOCH 3\n",
      "BEST AUC = 87.32 AT EPOCH 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_acc, val_loss, val_acc, train_auc, val_auc, best_dict = main(\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    n_epochs=4,\n",
    "    sample_size=0,\n",
    "    batch_size=64,\n",
    "    embed_dim=8,\n",
    "    num_heads=2,\n",
    "    num_blocks=2,\n",
    "    n_qubits_transformer=8,\n",
    "    n_qubits_ffn=8,\n",
    "    n_qlayers=3,\n",
    "    tqdm_disabled=False,\n",
    "    q_device=\"default.qubit.torch\",\n",
    "    batch=True,\n",
    "    circuit_type=\"pennylane\",\n",
    ")\n",
    "\n",
    "quantum_pl_gpu_metrics_batch = {\n",
    "    \"train_loss\": train_loss,\n",
    "    \"train_acc\": train_acc,\n",
    "    \"val_loss\": val_loss,\n",
    "    \"val_acc\": val_acc,\n",
    "    \"train_auc\": train_auc,\n",
    "    \"val_auc\": val_auc,\n",
    "    \"best_dict\": best_dict,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantum with Pennylane CPU and Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++ There will be 2 transformer blocks\n",
      "++ Transformer will use 8 qubits and 3 q layers\n",
      "The feed-forward head will use 8 qubits\n",
      "Using PennyLane quantum device default.qubit\n",
      "weight_shapes = (n_qlayers, n_qubits) = (3, 8)\n",
      "weight_shapes = (n_qlayers, n_qubits) = (3, 8)\n",
      "TextClassifier(\n",
      "  (squeeze): Linear(in_features=768, out_features=8, bias=True)\n",
      "  (transformers): ModuleList(\n",
      "    (0-1): 2 x Encoder(\n",
      "      (attn): MultiHeadedAttention(\n",
      "        (k_linear): QuantumLayer(\n",
      "          (linear): <Quantum Torch Layer: func=qlayer>\n",
      "        )\n",
      "        (q_linear): QuantumLayer(\n",
      "          (linear): <Quantum Torch Layer: func=qlayer>\n",
      "        )\n",
      "        (v_linear): QuantumLayer(\n",
      "          (linear): <Quantum Torch Layer: func=qlayer>\n",
      "        )\n",
      "        (combine_heads): QuantumLayer(\n",
      "          (linear): <Quantum Torch Layer: func=qlayer>\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (norm1): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout1): Dropout(p=0.1, inplace=False)\n",
      "      (ffn): FeedForward(\n",
      "        (linear_1): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (linear_2): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (vqc): QuantumLayer(\n",
      "          (linear): <Quantum Torch Layer: func=qlayer>\n",
      "        )\n",
      "        (gelu): GELU(approximate='none')\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (norm2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout2): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (layer_norm): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "  (class_logits): Linear(in_features=8, out_features=1, bias=True)\n",
      ")\n",
      "Layer Name                               Number of Parameters\n",
      "============================================================\n",
      "squeeze.weight                           6144\n",
      "squeeze.bias                             8\n",
      "transformers.0.attn.k_linear.linear.weights 24\n",
      "transformers.0.attn.q_linear.linear.weights 24\n",
      "transformers.0.attn.v_linear.linear.weights 24\n",
      "transformers.0.attn.combine_heads.linear.weights 24\n",
      "transformers.0.norm1.weight              8\n",
      "transformers.0.norm1.bias                8\n",
      "transformers.0.ffn.linear_1.weight       64\n",
      "transformers.0.ffn.linear_1.bias         8\n",
      "transformers.0.ffn.linear_2.weight       64\n",
      "transformers.0.ffn.linear_2.bias         8\n",
      "transformers.0.ffn.vqc.linear.weights    24\n",
      "transformers.0.norm2.weight              8\n",
      "transformers.0.norm2.bias                8\n",
      "transformers.1.attn.k_linear.linear.weights 24\n",
      "transformers.1.attn.q_linear.linear.weights 24\n",
      "transformers.1.attn.v_linear.linear.weights 24\n",
      "transformers.1.attn.combine_heads.linear.weights 24\n",
      "transformers.1.norm1.weight              8\n",
      "transformers.1.norm1.bias                8\n",
      "transformers.1.ffn.linear_1.weight       64\n",
      "transformers.1.ffn.linear_1.bias         8\n",
      "transformers.1.ffn.linear_2.weight       64\n",
      "transformers.1.ffn.linear_2.bias         8\n",
      "transformers.1.ffn.vqc.linear.weights    24\n",
      "transformers.1.norm2.weight              8\n",
      "transformers.1.norm2.bias                8\n",
      "layer_norm.weight                        8\n",
      "layer_norm.bias                          8\n",
      "class_logits.weight                      8\n",
      "class_logits.bias                        1\n",
      "The model has 6,769 trainable parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch   1/4: 100%|██████████| 313/313 [10:12<00:00,  1.96s/batch, Epoch = 10m 12s, Loss = 0.5999|0.4905, Acc = 0.670|0.763, AUC = 74.177|86.036]\n",
      "Epoch   2/4: 100%|██████████| 313/313 [10:19<00:00,  1.98s/batch, Epoch = 10m 19s, Loss = 0.5096|0.4613, Acc = 0.764|0.791, AUC = 82.943|87.084]\n",
      "Epoch   3/4: 100%|██████████| 313/313 [10:16<00:00,  1.97s/batch, Epoch = 10m 16s, Loss = 0.4899|0.4539, Acc = 0.775|0.789, AUC = 84.450|87.199]\n",
      "Epoch   4/4: 100%|██████████| 313/313 [10:14<00:00,  1.96s/batch, Epoch = 10m 14s, Loss = 0.4779|0.4630, Acc = 0.781|0.786, AUC = 85.321|87.129]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TIME = 2461.49s\n",
      "BEST ACC = 0.79% AT EPOCH 2\n",
      "BEST AUC = 87.20 AT EPOCH 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_acc, val_loss, val_acc, train_auc, val_auc, best_dict = main(\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    n_epochs=4,\n",
    "    sample_size=0,\n",
    "    batch_size=64,\n",
    "    embed_dim=8,\n",
    "    num_heads=2,\n",
    "    num_blocks=2,\n",
    "    n_qubits_transformer=8,\n",
    "    n_qubits_ffn=8,\n",
    "    n_qlayers=3,\n",
    "    tqdm_disabled=False,\n",
    "    q_device=\"default.qubit\",\n",
    "    batch=True,\n",
    "    circuit_type=\"pennylane\",\n",
    ")\n",
    "\n",
    "quantum_pl_cpu_metrics_batch = {\n",
    "    \"train_loss\": train_loss,\n",
    "    \"train_acc\": train_acc,\n",
    "    \"val_loss\": val_loss,\n",
    "    \"val_acc\": val_acc,\n",
    "    \"train_auc\": train_auc,\n",
    "    \"val_auc\": val_auc,\n",
    "    \"best_dict\": best_dict,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantum with Tensorcircuit (Tensorflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++ There will be 2 transformer blocks\n",
      "++ Transformer will use 8 qubits and 3 q layers\n",
      "The feed-forward head will use 8 qubits\n",
      "Using TensorCircuit\n",
      "weight_shapes = (n_qlayers, n_qubits) = (3, 8)\n",
      "weight_shapes = (n_qlayers, n_qubits) = (3, 8)\n",
      "TextClassifier(\n",
      "  (squeeze): Linear(in_features=768, out_features=8, bias=True)\n",
      "  (transformers): ModuleList(\n",
      "    (0-1): 2 x Encoder(\n",
      "      (attn): MultiHeadedAttention(\n",
      "        (k_linear): QuantumLayer()\n",
      "        (q_linear): QuantumLayer()\n",
      "        (v_linear): QuantumLayer()\n",
      "        (combine_heads): QuantumLayer()\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (norm1): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout1): Dropout(p=0.1, inplace=False)\n",
      "      (ffn): FeedForward(\n",
      "        (linear_1): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (linear_2): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (vqc): QuantumLayer()\n",
      "        (gelu): GELU(approximate='none')\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (norm2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout2): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (layer_norm): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "  (class_logits): Linear(in_features=8, out_features=1, bias=True)\n",
      ")\n",
      "Layer Name                               Number of Parameters\n",
      "============================================================\n",
      "squeeze.weight                           6144\n",
      "squeeze.bias                             8\n",
      "transformers.0.attn.k_linear.weights     24\n",
      "transformers.0.attn.q_linear.weights     24\n",
      "transformers.0.attn.v_linear.weights     24\n",
      "transformers.0.attn.combine_heads.weights 24\n",
      "transformers.0.norm1.weight              8\n",
      "transformers.0.norm1.bias                8\n",
      "transformers.0.ffn.linear_1.weight       64\n",
      "transformers.0.ffn.linear_1.bias         8\n",
      "transformers.0.ffn.linear_2.weight       64\n",
      "transformers.0.ffn.linear_2.bias         8\n",
      "transformers.0.ffn.vqc.weights           24\n",
      "transformers.0.norm2.weight              8\n",
      "transformers.0.norm2.bias                8\n",
      "transformers.1.attn.k_linear.weights     24\n",
      "transformers.1.attn.q_linear.weights     24\n",
      "transformers.1.attn.v_linear.weights     24\n",
      "transformers.1.attn.combine_heads.weights 24\n",
      "transformers.1.norm1.weight              8\n",
      "transformers.1.norm1.bias                8\n",
      "transformers.1.ffn.linear_1.weight       64\n",
      "transformers.1.ffn.linear_1.bias         8\n",
      "transformers.1.ffn.linear_2.weight       64\n",
      "transformers.1.ffn.linear_2.bias         8\n",
      "transformers.1.ffn.vqc.weights           24\n",
      "transformers.1.norm2.weight              8\n",
      "transformers.1.norm2.bias                8\n",
      "layer_norm.weight                        8\n",
      "layer_norm.bias                          8\n",
      "class_logits.weight                      8\n",
      "class_logits.bias                        1\n",
      "The model has 6,769 trainable parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch   1/4: 100%|██████████| 313/313 [2:37:17<00:00, 30.15s/batch, Epoch = 157m 17s, Loss = 0.5676|0.4785, Acc = 0.707|0.779, AUC = 77.924|86.119]\n",
      "Epoch   2/4: 100%|██████████| 313/313 [2:24:59<00:00, 27.79s/batch, Epoch = 144m 59s, Loss = 0.4972|0.4863, Acc = 0.769|0.777, AUC = 83.987|86.981]\n",
      "Epoch   3/4: 100%|██████████| 313/313 [2:17:24<00:00, 26.34s/batch, Epoch = 137m 24s, Loss = 0.4831|0.5067, Acc = 0.779|0.759, AUC = 84.999|87.571]\n",
      "Epoch   4/4: 100%|██████████| 313/313 [2:26:12<00:00, 28.03s/batch, Epoch = 146m 12s, Loss = 0.4759|0.4595, Acc = 0.781|0.792, AUC = 85.533|87.849]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TIME = 35153.40s\n",
      "BEST ACC = 0.79% AT EPOCH 4\n",
      "BEST AUC = 87.85 AT EPOCH 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_acc, val_loss, val_acc, train_auc, val_auc, best_dict = main(\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    n_epochs=4,\n",
    "    sample_size=0,\n",
    "    batch_size=64,\n",
    "    embed_dim=8,\n",
    "    num_heads=2,\n",
    "    num_blocks=2,\n",
    "    n_qubits_transformer=8,\n",
    "    n_qubits_ffn=8,\n",
    "    n_qlayers=3,\n",
    "    tqdm_disabled=False,\n",
    "    batch=False,\n",
    "    circuit_type=\"tensorcircuit\",\n",
    ")\n",
    "\n",
    "quantum_tc_cpu_metrics = {\n",
    "    \"train_loss\": train_loss,\n",
    "    \"train_acc\": train_acc,\n",
    "    \"val_loss\": val_loss,\n",
    "    \"val_acc\": val_acc,\n",
    "    \"train_auc\": train_auc,\n",
    "    \"val_auc\": val_auc,\n",
    "    \"best_dict\": best_dict,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantum with Tensorcircuit (Tensorflow) and Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++ There will be 2 transformer blocks\n",
      "++ Transformer will use 8 qubits and 3 q layers\n",
      "The feed-forward head will use 8 qubits\n",
      "Using TensorCircuit\n",
      "weight_shapes = (n_qlayers, n_qubits) = (3, 8)\n",
      "weight_shapes = (n_qlayers, n_qubits) = (3, 8)\n",
      "TextClassifier(\n",
      "  (squeeze): Linear(in_features=768, out_features=8, bias=True)\n",
      "  (transformers): ModuleList(\n",
      "    (0-1): 2 x Encoder(\n",
      "      (attn): MultiHeadedAttention(\n",
      "        (k_linear): QuantumLayer()\n",
      "        (q_linear): QuantumLayer()\n",
      "        (v_linear): QuantumLayer()\n",
      "        (combine_heads): QuantumLayer()\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (norm1): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout1): Dropout(p=0.1, inplace=False)\n",
      "      (ffn): FeedForward(\n",
      "        (linear_1): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (linear_2): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (vqc): QuantumLayer()\n",
      "        (gelu): GELU(approximate='none')\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (norm2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout2): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (layer_norm): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "  (class_logits): Linear(in_features=8, out_features=1, bias=True)\n",
      ")\n",
      "Layer Name                               Number of Parameters\n",
      "============================================================\n",
      "squeeze.weight                           6144\n",
      "squeeze.bias                             8\n",
      "transformers.0.attn.k_linear.weights     24\n",
      "transformers.0.attn.q_linear.weights     24\n",
      "transformers.0.attn.v_linear.weights     24\n",
      "transformers.0.attn.combine_heads.weights 24\n",
      "transformers.0.norm1.weight              8\n",
      "transformers.0.norm1.bias                8\n",
      "transformers.0.ffn.linear_1.weight       64\n",
      "transformers.0.ffn.linear_1.bias         8\n",
      "transformers.0.ffn.linear_2.weight       64\n",
      "transformers.0.ffn.linear_2.bias         8\n",
      "transformers.0.ffn.vqc.weights           24\n",
      "transformers.0.norm2.weight              8\n",
      "transformers.0.norm2.bias                8\n",
      "transformers.1.attn.k_linear.weights     24\n",
      "transformers.1.attn.q_linear.weights     24\n",
      "transformers.1.attn.v_linear.weights     24\n",
      "transformers.1.attn.combine_heads.weights 24\n",
      "transformers.1.norm1.weight              8\n",
      "transformers.1.norm1.bias                8\n",
      "transformers.1.ffn.linear_1.weight       64\n",
      "transformers.1.ffn.linear_1.bias         8\n",
      "transformers.1.ffn.linear_2.weight       64\n",
      "transformers.1.ffn.linear_2.bias         8\n",
      "transformers.1.ffn.vqc.weights           24\n",
      "transformers.1.norm2.weight              8\n",
      "transformers.1.norm2.bias                8\n",
      "layer_norm.weight                        8\n",
      "layer_norm.bias                          8\n",
      "class_logits.weight                      8\n",
      "class_logits.bias                        1\n",
      "The model has 6,769 trainable parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch   1/4:   0%|          | 0/313 [00:00<?, ?batch/s]2024-10-04 22:31:19.830456: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2024-10-04 22:31:19.833088: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20478 MB memory:  -> device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:3b:00.0, compute capability: 7.0\n",
      "2024-10-04 22:31:19.838258: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2024-10-04 22:31:19.838649: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 31134 MB memory:  -> device: 1, name: Tesla V100-PCIE-32GB, pci bus id: 0000:d8:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowBackend.vmap.<locals>.wrapper at 0x7f0574560360> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowBackend.vmap.<locals>.wrapper at 0x7f0574561940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function torch_interface.<locals>.vjp_fun at 0x7f0574560400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function torch_interface.<locals>.vjp_fun at 0x7f0574561ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch   1/4: 100%|██████████| 313/313 [07:19<00:00,  1.40s/batch, Epoch = 7m 19s, Loss = 0.5711|0.4769, Acc = 0.713|0.779, AUC = 77.818|85.995]\n",
      "Epoch   2/4: 100%|██████████| 313/313 [02:58<00:00,  1.75batch/s, Epoch = 2m 58s, Loss = 0.5135|0.4690, Acc = 0.760|0.784, AUC = 82.637|86.629]\n",
      "Epoch   3/4: 100%|██████████| 313/313 [03:02<00:00,  1.72batch/s, Epoch = 3m 2s, Loss = 0.4904|0.4762, Acc = 0.781|0.777, AUC = 84.328|87.030]\n",
      "Epoch   4/4: 100%|██████████| 313/313 [03:08<00:00,  1.66batch/s, Epoch = 3m 8s, Loss = 0.4767|0.4806, Acc = 0.786|0.783, AUC = 85.287|87.482]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TIME = 988.26s\n",
      "BEST ACC = 0.78% AT EPOCH 2\n",
      "BEST AUC = 87.48 AT EPOCH 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_acc, val_loss, val_acc, train_auc, val_auc, best_dict = main(\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    n_epochs=4,\n",
    "    sample_size=0,\n",
    "    batch_size=64,\n",
    "    embed_dim=8,\n",
    "    num_heads=2,\n",
    "    num_blocks=2,\n",
    "    n_qubits_transformer=8,\n",
    "    n_qubits_ffn=8,\n",
    "    n_qlayers=3,\n",
    "    tqdm_disabled=False,\n",
    "    batch=True,\n",
    "    circuit_type=\"tensorcircuit\",\n",
    ")\n",
    "\n",
    "quantum_tc_cpu_metrics_batch = {\n",
    "    \"train_loss\": train_loss,\n",
    "    \"train_acc\": train_acc,\n",
    "    \"val_loss\": val_loss,\n",
    "    \"val_acc\": val_acc,\n",
    "    \"train_auc\": train_auc,\n",
    "    \"val_auc\": val_auc,\n",
    "    \"best_dict\": best_dict,\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
