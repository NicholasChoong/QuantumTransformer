Working SCRATCH directory is /scratch/pmc026/nchoong/run_conda/522213
Results will be stored in /group/pmc026/nchoong/QuantumTransformer/conda_results/522213
SLURM_SUBMIT_DIR is
/group/pmc026/nchoong/QuantumTransformer
total 140
drwxrwxr-x  3 nchoong nchoong      0 Oct  6 02:53 .
drwxrwxr-x 12 nchoong nchoong      0 Oct  6 02:53 ..
-rw-r--r--  1 nchoong nchoong 142510 Oct  6 02:53 amazon-amplitude.ipynb
-rw-rw-r--  1 nchoong nchoong    173 Oct  6 02:53 config.py
drwxr-xr-x  4 nchoong nchoong      0 Oct  6 02:53 transformer
Sun Oct  6 02:53:18 2024       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.54.14              Driver Version: 550.54.14      CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla V100-PCIE-32GB           Off |   00000000:3B:00.0 Off |                    0 |
| N/A   39C    P0             37W /  250W |       0MiB /  32768MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  Tesla V100-PCIE-32GB           Off |   00000000:D8:00.0 Off |                    0 |
| N/A   32C    P0             25W /  250W |       0MiB /  32768MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
Input Notebook:  ./amazon-amplitude.ipynb
Output Notebook: ./amazon-amplitude.papermill.ipynb
Executing:   0%|          | 0/11 [00:00<?, ?cell/s]Executing notebook with kernel: python3
Executing:   9%|▉         | 1/11 [00:03<00:34,  3.43s/cell]2024-10-06 02:53:35.032159: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-10-06 02:53:35.047914: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-10-06 02:53:35.063769: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-10-06 02:53:35.068642: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-10-06 02:53:35.097959: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-10-06 02:53:38.478498: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Executing:  27%|██▋       | 3/11 [00:23<01:06,  8.26s/cell]Executing:  64%|██████▎   | 7/11 [40:40<27:32, 413.12s/cell]Executing:  82%|████████▏ | 9/11 [7:23:11<2:20:44, 4222.41s/cell]Executing:  91%|█████████ | 10/11 [7:23:12<57:03, 3423.75s/cell] Wait for final termination of kernel timed out - continuing...
Executing: 100%|██████████| 11/11 [7:23:22<00:00, 2418.43s/cell]
mv /scratch/pmc026/nchoong/run_conda/522213 /group/pmc026/nchoong/QuantumTransformer/conda_results
Please see the /group/pmc026/nchoong/QuantumTransformer/conda_results directory for any output

Mothur MPI job started  at Sun Oct  6 02:53:17 AWST 2024
Mothur MPI job finished at Sun Oct  6 10:16:45 AWST 2024
