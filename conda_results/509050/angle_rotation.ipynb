{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/group/pmc026/nchoong/QuantumTransformer'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.chdir(\"..\")\n",
    "sys.path.append(os.getcwd())\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/group/pmc026/nchoong\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/group/pmc026/nchoong/QuantumTransformer/data/word_embeddings/imdb_train_batch_0.pt',\n",
       " '/group/pmc026/nchoong/QuantumTransformer/data/word_embeddings/imdb_train_batch_1.pt',\n",
       " '/group/pmc026/nchoong/QuantumTransformer/data/word_embeddings/imdb_train_batch_2.pt',\n",
       " '/group/pmc026/nchoong/QuantumTransformer/data/word_embeddings/imdb_train_batch_3.pt',\n",
       " '/group/pmc026/nchoong/QuantumTransformer/data/word_embeddings/imdb_train_batch_4.pt',\n",
       " '/group/pmc026/nchoong/QuantumTransformer/data/word_embeddings/imdb_train_batch_5.pt',\n",
       " '/group/pmc026/nchoong/QuantumTransformer/data/word_embeddings/imdb_train_batch_6.pt']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "group_dir = os.getenv(\"MYGROUP\")\n",
    "glob.glob(f\"{group_dir}/QuantumTransformer/data/word_embeddings/imdb_train_batch_*.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-29 10:16:45.550354: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-29 10:16:46.355022: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-29 10:16:46.650578: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-29 10:16:46.736333: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-29 10:16:47.340695: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-29 10:16:51.881425: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Please first ``pip install -U qiskit`` to enable related functionality in translation module\n"
     ]
    }
   ],
   "source": [
    "from transformer.pytorch.main_no_embed import main\n",
    "from transformer.pytorch.utils.load_dataloader import load_dataloader\n",
    "from transformer.pytorch.utils.plots import plot_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from config import dev\n",
    "\n",
    "dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "os.environ[\"TF_DETERMINISTIC_OPS\"] = \"1\"\n",
    "os.environ[\"TF_CUDNN_DETERMINISTIC\"] = \"1\"\n",
    "tf.config.threading.set_inter_op_parallelism_threads(1)\n",
    "tf.config.threading.set_intra_op_parallelism_threads(1)\n",
    "\n",
    "os.environ[\"OMP_NUM_THREADS\"] = str(os.cpu_count())\n",
    "os.environ[\"TF_NUM_INTEROP_THREADS\"] = str(os.cpu_count())\n",
    "os.environ[\"TF_NUM_INTRAOP_THREADS\"] = str(os.cpu_count())\n",
    "\n",
    "tf.config.threading.set_intra_op_parallelism_threads(os.cpu_count())\n",
    "tf.config.threading.set_inter_op_parallelism_threads(os.cpu_count())\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading train tensors: 100%|██████████| 7/7 [00:21<00:00,  3.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size:  20000\n",
      "Total RAM: 754.38 GB\n",
      "Available RAM: 690.70 GB\n",
      "Used RAM: 37.58 GB\n",
      "RAM Usage Percentage: 8.4%\n",
      "Sample size:  5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading val tensors: 100%|██████████| 2/2 [00:05<00:00,  2.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val size:  5000\n",
      "Val size:  5000\n",
      "Total RAM: 754.38 GB\n",
      "Available RAM: 678.52 GB\n",
      "Used RAM: 49.75 GB\n",
      "RAM Usage Percentage: 10.1%\n",
      "Total RAM: 754.38 GB\n",
      "Available RAM: 680.19 GB\n",
      "Used RAM: 48.08 GB\n",
      "RAM Usage Percentage: 9.8%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading test tensors: 100%|██████████| 9/9 [00:26<00:00,  2.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test size:  5000\n",
      "Train, Val, Test size:  20000 5000 5000\n",
      "pos:  10006\n",
      "neg:  9994\n",
      "pos:  2494\n",
      "neg:  2506\n",
      "pos:  2494\n",
      "neg:  2506\n"
     ]
    }
   ],
   "source": [
    "train_dataloader, val_dataloader, test_dataloader = load_dataloader(\"imdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++ There will be 2 transformer blocks\n",
      "++ Transformer will use 8 qubits and 3 q layers\n",
      "The feed-forward head will use 8 qubits\n",
      "Using PennyLane quantum device default.qubit.torch\n",
      "weight_shapes = (n_qlayers, n_qubits) = (3, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/group/pmc026/nchoong/qt/lib/python3.11/site-packages/pennylane/devices/default_qubit_torch.py:173: PennyLaneDeprecationWarning: Use of 'default.qubit.torch' is deprecated. Instead, use 'default.qubit', which supports backpropagation. If you experience issues, reach out to the PennyLane team on the discussion forum: https://discuss.pennylane.ai/\n",
      "  warnings.warn(\n",
      "/group/pmc026/nchoong/qt/lib/python3.11/site-packages/pennylane/devices/default_qubit_legacy.py:211: PennyLaneDeprecationWarning: Use of 'default.qubit.torch' is deprecated. Instead, use 'default.qubit', which supports backpropagation. If you experience issues, reach out to the PennyLane team on the discussion forum: https://discuss.pennylane.ai/\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight_shapes = (n_qlayers, n_qubits) = (3, 8)\n",
      "The model has 6,769 trainable parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch   1/4:   7%|▋         | 43/625 [00:43<09:44,  1.00s/batch]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_loss, train_acc, val_loss, val_acc, train_auc, val_auc, best_dict \u001b[38;5;241m=\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43membed_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_blocks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_qubits_transformer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_qubits_ffn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_qlayers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtqdm_disabled\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mq_device\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdefault.qubit.torch\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcircuit_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpennylane\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpennylane_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mangle_rot\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrot\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m quantum_pl_gpu_metrics_batch \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m: train_loss,\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_acc\u001b[39m\u001b[38;5;124m\"\u001b[39m: train_acc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m: best_dict,\n\u001b[1;32m     29\u001b[0m }\n",
      "File \u001b[0;32m/group/pmc026/nchoong/QuantumTransformer/transformer/pytorch/main_no_embed.py:100\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(train_dataloader, val_dataloader, test_dataloader, max_seq_len, batch_size, sample_size, n_epochs, lr, embed_dim, num_heads, num_blocks, num_classes, vocab_size, ffn_dim, n_qubits_transformer, n_qubits_ffn, n_qlayers, dropout_rate, tqdm_disabled, q_device, batch, circuit_type, pennylane_args, multi_gpu)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tqdm(\n\u001b[1;32m     92\u001b[0m     total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_dataloader),\n\u001b[1;32m     93\u001b[0m     desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00miepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m3\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     96\u001b[0m     disable\u001b[38;5;241m=\u001b[39mtqdm_disabled,\n\u001b[1;32m     97\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m progress_bar:\n\u001b[1;32m     98\u001b[0m     operation_start_time \u001b[38;5;241m=\u001b[39m time()\n\u001b[0;32m--> 100\u001b[0m     train_loss, train_acc, train_auc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_seq_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m     progress_bar\u001b[38;5;241m.\u001b[39mset_postfix_str((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluating on validation set...\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    112\u001b[0m     val_loss, val_acc, val_auc \u001b[38;5;241m=\u001b[39m evaluate(\n\u001b[1;32m    113\u001b[0m         model, val_dataloader, criterion, max_seq_len\n\u001b[1;32m    114\u001b[0m     )\n",
      "File \u001b[0;32m/group/pmc026/nchoong/QuantumTransformer/transformer/pytorch/utils/train_no_embed.py:47\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, dataloader, optimizer, criterion, scheduler, max_seq_len, batch_size, progress_bar)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# loss = F.nll_loss(predictions, label)\u001b[39;00m\n\u001b[1;32m     45\u001b[0m acc \u001b[38;5;241m=\u001b[39m binary_accuracy(predictions, label)\n\u001b[0;32m---> 47\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     50\u001b[0m epoch_loss\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[0;32m/group/pmc026/nchoong/qt/lib/python3.11/site-packages/torch/_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[0;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/group/pmc026/nchoong/qt/lib/python3.11/site-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/group/pmc026/nchoong/qt/lib/python3.11/site-packages/torch/autograd/graph.py:769\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    767\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    770\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loss, train_acc, val_loss, val_acc, train_auc, val_auc, best_dict = main(\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    n_epochs=20,\n",
    "    sample_size=0,\n",
    "    batch_size=64,\n",
    "    embed_dim=8,\n",
    "    num_heads=2,\n",
    "    num_blocks=2,\n",
    "    n_qubits_transformer=8,\n",
    "    n_qubits_ffn=8,\n",
    "    n_qlayers=3,\n",
    "    tqdm_disabled=True,\n",
    "    q_device=\"default.qubit.torch\",\n",
    "    batch=True,\n",
    "    circuit_type=\"pennylane\",\n",
    "    pennylane_args={\"angle_rot\": \"X\", \"rot\": \"X\"},\n",
    ")\n",
    "\n",
    "quantum_pl_gpu_metrics_batch = {\n",
    "    \"train_loss\": train_loss,\n",
    "    \"train_acc\": train_acc,\n",
    "    \"val_loss\": val_loss,\n",
    "    \"val_acc\": val_acc,\n",
    "    \"train_auc\": train_auc,\n",
    "    \"val_auc\": val_auc,\n",
    "    \"best_dict\": best_dict,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(train_loss, val_loss, train_acc, val_acc, train_auc, val_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, train_acc, val_loss, val_acc, train_auc, val_auc, best_dict = main(\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    n_epochs=20,\n",
    "    sample_size=0,\n",
    "    batch_size=64,\n",
    "    embed_dim=8,\n",
    "    num_heads=2,\n",
    "    num_blocks=2,\n",
    "    n_qubits_transformer=8,\n",
    "    n_qubits_ffn=8,\n",
    "    n_qlayers=3,\n",
    "    tqdm_disabled=True,\n",
    "    q_device=\"default.qubit.torch\",\n",
    "    batch=True,\n",
    "    circuit_type=\"pennylane\",\n",
    "    pennylane_args={\"angle_rot\": \"Y\", \"rot\": \"X\"},\n",
    ")\n",
    "\n",
    "quantum_pl_gpu_metrics_batch = {\n",
    "    \"train_loss\": train_loss,\n",
    "    \"train_acc\": train_acc,\n",
    "    \"val_loss\": val_loss,\n",
    "    \"val_acc\": val_acc,\n",
    "    \"train_auc\": train_auc,\n",
    "    \"val_auc\": val_auc,\n",
    "    \"best_dict\": best_dict,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(train_loss, val_loss, train_acc, val_acc, train_auc, val_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, train_acc, val_loss, val_acc, train_auc, val_auc, best_dict = main(\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    n_epochs=20,\n",
    "    sample_size=0,\n",
    "    batch_size=64,\n",
    "    embed_dim=8,\n",
    "    num_heads=2,\n",
    "    num_blocks=2,\n",
    "    n_qubits_transformer=8,\n",
    "    n_qubits_ffn=8,\n",
    "    n_qlayers=3,\n",
    "    tqdm_disabled=True,\n",
    "    q_device=\"default.qubit.torch\",\n",
    "    batch=True,\n",
    "    circuit_type=\"pennylane\",\n",
    "    pennylane_args={\"angle_rot\": \"Z\", \"rot\": \"X\"},\n",
    ")\n",
    "\n",
    "quantum_pl_gpu_metrics_batch = {\n",
    "    \"train_loss\": train_loss,\n",
    "    \"train_acc\": train_acc,\n",
    "    \"val_loss\": val_loss,\n",
    "    \"val_acc\": val_acc,\n",
    "    \"train_auc\": train_auc,\n",
    "    \"val_auc\": val_auc,\n",
    "    \"best_dict\": best_dict,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(train_loss, val_loss, train_acc, val_acc, train_auc, val_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, train_acc, val_loss, val_acc, train_auc, val_auc, best_dict = main(\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    n_epochs=20,\n",
    "    sample_size=0,\n",
    "    batch_size=64,\n",
    "    embed_dim=8,\n",
    "    num_heads=2,\n",
    "    num_blocks=2,\n",
    "    n_qubits_transformer=8,\n",
    "    n_qubits_ffn=8,\n",
    "    n_qlayers=3,\n",
    "    tqdm_disabled=True,\n",
    "    q_device=\"default.qubit.torch\",\n",
    "    batch=True,\n",
    "    circuit_type=\"pennylane\",\n",
    "    pennylane_args={\"angle_rot\": \"X\", \"rot\": \"Y\"},\n",
    ")\n",
    "\n",
    "quantum_pl_gpu_metrics_batch = {\n",
    "    \"train_loss\": train_loss,\n",
    "    \"train_acc\": train_acc,\n",
    "    \"val_loss\": val_loss,\n",
    "    \"val_acc\": val_acc,\n",
    "    \"train_auc\": train_auc,\n",
    "    \"val_auc\": val_auc,\n",
    "    \"best_dict\": best_dict,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(train_loss, val_loss, train_acc, val_acc, train_auc, val_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, train_acc, val_loss, val_acc, train_auc, val_auc, best_dict = main(\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    n_epochs=20,\n",
    "    sample_size=0,\n",
    "    batch_size=64,\n",
    "    embed_dim=8,\n",
    "    num_heads=2,\n",
    "    num_blocks=2,\n",
    "    n_qubits_transformer=8,\n",
    "    n_qubits_ffn=8,\n",
    "    n_qlayers=3,\n",
    "    tqdm_disabled=True,\n",
    "    q_device=\"default.qubit.torch\",\n",
    "    batch=True,\n",
    "    circuit_type=\"pennylane\",\n",
    "    pennylane_args={\"angle_rot\": \"Y\", \"rot\": \"Y\"},\n",
    ")\n",
    "\n",
    "quantum_pl_gpu_metrics_batch = {\n",
    "    \"train_loss\": train_loss,\n",
    "    \"train_acc\": train_acc,\n",
    "    \"val_loss\": val_loss,\n",
    "    \"val_acc\": val_acc,\n",
    "    \"train_auc\": train_auc,\n",
    "    \"val_auc\": val_auc,\n",
    "    \"best_dict\": best_dict,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(train_loss, val_loss, train_acc, val_acc, train_auc, val_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, train_acc, val_loss, val_acc, train_auc, val_auc, best_dict = main(\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    n_epochs=20,\n",
    "    sample_size=0,\n",
    "    batch_size=64,\n",
    "    embed_dim=8,\n",
    "    num_heads=2,\n",
    "    num_blocks=2,\n",
    "    n_qubits_transformer=8,\n",
    "    n_qubits_ffn=8,\n",
    "    n_qlayers=3,\n",
    "    tqdm_disabled=True,\n",
    "    q_device=\"default.qubit.torch\",\n",
    "    batch=True,\n",
    "    circuit_type=\"pennylane\",\n",
    "    pennylane_args={\"angle_rot\": \"Z\", \"rot\": \"Y\"},\n",
    ")\n",
    "\n",
    "quantum_pl_gpu_metrics_batch = {\n",
    "    \"train_loss\": train_loss,\n",
    "    \"train_acc\": train_acc,\n",
    "    \"val_loss\": val_loss,\n",
    "    \"val_acc\": val_acc,\n",
    "    \"train_auc\": train_auc,\n",
    "    \"val_auc\": val_auc,\n",
    "    \"best_dict\": best_dict,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(train_loss, val_loss, train_acc, val_acc, train_auc, val_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, train_acc, val_loss, val_acc, train_auc, val_auc, best_dict = main(\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    n_epochs=20,\n",
    "    sample_size=0,\n",
    "    batch_size=64,\n",
    "    embed_dim=8,\n",
    "    num_heads=2,\n",
    "    num_blocks=2,\n",
    "    n_qubits_transformer=8,\n",
    "    n_qubits_ffn=8,\n",
    "    n_qlayers=3,\n",
    "    tqdm_disabled=True,\n",
    "    q_device=\"default.qubit.torch\",\n",
    "    batch=True,\n",
    "    circuit_type=\"pennylane\",\n",
    "    pennylane_args={\"angle_rot\": \"X\", \"rot\": \"Z\"},\n",
    ")\n",
    "\n",
    "quantum_pl_gpu_metrics_batch = {\n",
    "    \"train_loss\": train_loss,\n",
    "    \"train_acc\": train_acc,\n",
    "    \"val_loss\": val_loss,\n",
    "    \"val_acc\": val_acc,\n",
    "    \"train_auc\": train_auc,\n",
    "    \"val_auc\": val_auc,\n",
    "    \"best_dict\": best_dict,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(train_loss, val_loss, train_acc, val_acc, train_auc, val_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, train_acc, val_loss, val_acc, train_auc, val_auc, best_dict = main(\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    n_epochs=20,\n",
    "    sample_size=0,\n",
    "    batch_size=64,\n",
    "    embed_dim=8,\n",
    "    num_heads=2,\n",
    "    num_blocks=2,\n",
    "    n_qubits_transformer=8,\n",
    "    n_qubits_ffn=8,\n",
    "    n_qlayers=3,\n",
    "    tqdm_disabled=True,\n",
    "    q_device=\"default.qubit.torch\",\n",
    "    batch=True,\n",
    "    circuit_type=\"pennylane\",\n",
    "    pennylane_args={\"angle_rot\": \"Y\", \"rot\": \"Z\"},\n",
    ")\n",
    "\n",
    "quantum_pl_gpu_metrics_batch = {\n",
    "    \"train_loss\": train_loss,\n",
    "    \"train_acc\": train_acc,\n",
    "    \"val_loss\": val_loss,\n",
    "    \"val_acc\": val_acc,\n",
    "    \"train_auc\": train_auc,\n",
    "    \"val_auc\": val_auc,\n",
    "    \"best_dict\": best_dict,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(train_loss, val_loss, train_acc, val_acc, train_auc, val_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, train_acc, val_loss, val_acc, train_auc, val_auc, best_dict = main(\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    n_epochs=20,\n",
    "    sample_size=0,\n",
    "    batch_size=64,\n",
    "    embed_dim=8,\n",
    "    num_heads=2,\n",
    "    num_blocks=2,\n",
    "    n_qubits_transformer=8,\n",
    "    n_qubits_ffn=8,\n",
    "    n_qlayers=3,\n",
    "    tqdm_disabled=True,\n",
    "    q_device=\"default.qubit.torch\",\n",
    "    batch=True,\n",
    "    circuit_type=\"pennylane\",\n",
    "    pennylane_args={\"angle_rot\": \"Z\", \"rot\": \"Z\"},\n",
    ")\n",
    "\n",
    "quantum_pl_gpu_metrics_batch = {\n",
    "    \"train_loss\": train_loss,\n",
    "    \"train_acc\": train_acc,\n",
    "    \"val_loss\": val_loss,\n",
    "    \"val_acc\": val_acc,\n",
    "    \"train_auc\": train_auc,\n",
    "    \"val_auc\": val_auc,\n",
    "    \"best_dict\": best_dict,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(train_loss, val_loss, train_acc, val_acc, train_auc, val_auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
